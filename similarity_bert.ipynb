{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "import re\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import nltk\n",
    "import statsmodels.api as sm\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess_tasks(func, tasks, data, njobs=cpu_count()):\n",
    "    wrapper = partial(func, df=data)\n",
    "    res = []\n",
    "    with Pool(processes=njobs) as p:\n",
    "        n = len(tasks)\n",
    "        with tqdm(total=n) as pbar:\n",
    "            for i, v in enumerate(p.imap_unordered(wrapper, tasks)):\n",
    "                res.append(v)\n",
    "                pbar.update()\n",
    "    return res\n",
    "\n",
    "def divide_chunks(l, n): \n",
    "    # looping till length l \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n]\n",
    "\n",
    "def r_squared_adj(data, group, dummy=True, var_name=\"palt\"):\n",
    "    y = data[var_name]\n",
    "    if dummy:\n",
    "        x = data[group]\n",
    "    else:\n",
    "        x = pd.get_dummies(data[group], drop_first=True)\n",
    "    x = sm.add_constant(x)\n",
    "    mod = sm.OLS(y, x).fit()\n",
    "    return mod.rsquared_adj.round(2)\n",
    "\n",
    "\n",
    "def match_token(text, token):\n",
    "    tokens = tokenize_only(text)\n",
    "    if token in tokens:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def token_power(token, df, desc_column=\"award_description\"):\n",
    "    df[token] = df[desc_column].apply(match_token, token=token)\n",
    "    r2 = r_squared_adj(df, token)\n",
    "    return {token: r2}\n",
    "\n",
    "\n",
    "def tokenize_and_stem(text, stopwords=None):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [\n",
    "        word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)\n",
    "    ]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search(\"[a-zA-Z]\", token):\n",
    "            filtered_tokens.append(token)\n",
    "    if stopwords:\n",
    "        stems = [stemmer.stem(t) for t in filtered_tokens if t not in stopwords]\n",
    "    else:\n",
    "        stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text, stopwords=None):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [\n",
    "        word.lower()\n",
    "        for sent in nltk.sent_tokenize(text)\n",
    "        for word in nltk.word_tokenize(sent)\n",
    "    ]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search(\"[a-zA-Z]\", token):\n",
    "            filtered_tokens.append(token)\n",
    "    if stopwords:\n",
    "        r = [i for i in filtered_tokens if i not in stopwords]\n",
    "    else:\n",
    "        r = filtered_tokens\n",
    "    return r\n",
    "\n",
    "def top_n_sim(award_desc, award_desc_dict, sim_mat, n):\n",
    "    idx = int([i for i, v in award_desc_dict.items() if v == award_desc][0])\n",
    "    v = sim_mat[idx, :]\n",
    "    n_idx = np.argpartition(v, -n)[-n:]\n",
    "    r = [award_desc_dict[str(i)] for i in np.array(n_idx)]\n",
    "    return r\n",
    "\n",
    "def bert_sent_embedding(sentence_list, hidden_layer=-2):\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    # Tokenize and return tensors\n",
    "    batch = tokenizer(sentence_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained(\n",
    "        \"bert-base-uncased\",\n",
    "        output_hidden_states=True,\n",
    "    )\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all layers.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        # Evaluating the model will return a different number of objects based on\n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case,\n",
    "        # becase we set `output_hidden_states = True`, the third item will be the\n",
    "        # hidden states from all layers.\n",
    "        hidden_states = outputs[2]\n",
    "    # Extract the second to last layer\n",
    "    token_vecs = hidden_states[hidden_layer]\n",
    "    # Calculate the average of all sentence token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=1)\n",
    "    return sentence_embedding\n",
    "\n",
    "\n",
    "def pairwise_cosine_similarity(tensor, feature_dim=1, use_cuda=None):\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        print(\"Using Numpy\")\n",
    "        n = np.linalg.norm(tensor, axis=feature_dim, keepdims=True)\n",
    "        norm_tensor = tensor / n\n",
    "        r = np.dot(norm_tensor, norm_tensor.T)\n",
    "    elif isinstance(tensor, torch.Tensor):\n",
    "        if use_cuda:\n",
    "            print(\"Using PyTorch with CUDA\")\n",
    "            tensor = tensor.cuda()\n",
    "        else:\n",
    "            print(\"Using PyTorch with CPU\")\n",
    "        n = torch.norm(tensor, dim=feature_dim, keepdim=True)\n",
    "        norm_tensor = tensor / n\n",
    "        r = torch.matmul(norm_tensor, norm_tensor.T)\n",
    "    else:\n",
    "        raise (\"Unknown input data type\")\n",
    "    return r\n",
    "\n",
    "def top_n_sim(award_desc, award_desc_dict, sim_mat, n):\n",
    "    idx = int([i for i, v in award_desc_dict.items() if v == award_desc][0])\n",
    "    v = sim_mat[idx, :]\n",
    "    n_idx = np.argpartition(v, -n)[-n:]\n",
    "    r = [award_desc_dict[str(i)] for i in np.array(n_idx)]\n",
    "    return r\n",
    "\n",
    "def similar_records_bert(\n",
    "    top_n, award_description, records=None, model=\"distilbert-base-nli-mean-tokens\"\n",
    "):\n",
    "    if model in (\n",
    "        \"distilbert-base-nli-mean-tokens\",\n",
    "        \"paraphrase-distilroberta-base-v1\",\n",
    "        \"paraphrase-xlm-r-multilingual-v1\",\n",
    "        \"stsb-roberta-large\",\n",
    "        \"stsb-roberta-base\",\n",
    "        \"stsb-distilbert-base\",\n",
    "        \"stsb-bert-large\",\n",
    "        \"msmarco-distilroberta-base-v2\",\n",
    "        \"msmarco-roberta-base-v2\",\n",
    "        \"msmarco-distilbert-base-v2\",\n",
    "        \"nq-distilbert-base-v1\",\n",
    "    ):\n",
    "        model = SentenceTransformer(model)\n",
    "        record_embedding = model.encode(records[\"award_description\"])\n",
    "        new_case_embedding = model.encode(award_description)\n",
    "        sim = cosine_similarity(new_case_embedding, record_embedding)\n",
    "    else:\n",
    "        new_case_embedding = bert_sent_embedding(award_description)\n",
    "        sim = cosine_similarity(\n",
    "            new_case_embedding,\n",
    "            records[records.columns[records.columns.str.contains(\"bert_feat_\")]],\n",
    "        )\n",
    "    r = []\n",
    "    if isinstance(award_description, list):\n",
    "        for i in range(sim.shape[0]):\n",
    "            n_idx = np.argpartition(sim[i, :], -top_n)[-top_n:]\n",
    "            r.append(records.iloc[n_idx])\n",
    "    else:\n",
    "        n_idx = np.argpartition(sim[0, :], -top_n)[-top_n:]\n",
    "        r = records.iloc[n_idx]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process award description of IRS contracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 284)\n"
     ]
    }
   ],
   "source": [
    "# read in all contracts\n",
    "dfs = []\n",
    "for fp in glob.glob('../data/treasury/*.zip'):\n",
    "    if '2019' in fp or '2020' in fp:\n",
    "        df = pd.read_csv(fp, low_memory=False, dtype={'modification_number':str, 'parent_award_agency_id':str, 'awarding_sub_agency_code':str, 'funding_sub_agency_code':str})\n",
    "        df['fy'] = os.path.basename(fp)[2:6]\n",
    "        dfs.append(df)\n",
    "dat = pd.concat(dfs)\n",
    "\n",
    "# IRS contracts only\n",
    "dat = dat.loc[(dat.modification_number=='0')&((dat.parent_award_agency_id=='2050')|(dat.awarding_sub_agency_code=='2050')|(dat.funding_sub_agency_code=='2050'))]\n",
    "# treasury contracts\n",
    "# dat = dat.loc[(dat.modification_number=='0')]\n",
    "\n",
    "dat['action_date'] = pd.to_datetime(dat['action_date'])\n",
    "dat['solicitation_date'] = pd.to_datetime(dat['solicitation_date'])\n",
    "dat['palt'] = (dat['action_date'] - dat['solicitation_date']).dt.days\n",
    "dat = dat.loc[dat.palt.notnull()].reset_index(drop=True)\n",
    "\n",
    "# # select 95%tile for outlier cutoff\n",
    "palt = dat.loc[dat.palt<500].reset_index(drop=True)\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract contextualized word embedding features using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:49, 11.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "# write award_description into json file\n",
    "batch_sent = dat.award_description.tolist()\n",
    "\n",
    "with open('bert/award_desc.json', 'w') as f:\n",
    "    json.dump({i:v for i, v in enumerate(batch_sent)}, f)\n",
    "    \n",
    "# create award_description dictionary\n",
    "with open('bert/award_desc.json', 'r') as f:\n",
    "    award_desc_dict = json.load(f)\n",
    "    \n",
    "batches = divide_chunks(batch_sent, 100)\n",
    "\n",
    "# bert embedding\n",
    "%time bert_embed = [bert_sent_embedding(i) for i in tqdm(batches)]\n",
    "\n",
    "bert_embeddings = torch.cat(bert_embed, 0)\n",
    "\n",
    "bert_feat = pd.DataFrame(bert_embeddings.numpy(), columns=['bert_feat_'+str(i) for i in range(bert_embeddings.shape[1])])\n",
    "bert_feat.to_csv('bert/bert_embed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure and rank order similarity between IRS contracts and any individual contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Numpy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['WMQ BILLABLE SOFTWARE RENEWAL',\n",
       " 'NSHIELD CONNECT 6000+F3(PREMIUM SUPPORT)',\n",
       " 'ADVANCE EDITION SERVER LICENSE MAINTENANCE PACK',\n",
       " 'RRAC ACCESS-GEN LICENSE RENEWAL',\n",
       " 'AUTHENTIC8 SECURE INTERNET BROWSER ACCESS SOFTWARE AND SUPPORT-BASE PLUS TWO (2) OPTIONS',\n",
       " 'IDG SERVERS SUPPORT',\n",
       " 'ADMINSTUDIO SOFTWARE MAINTENANCE RENEWAL (12 MONTHS)',\n",
       " 'ACA DATA ANALYSIS - BASE YEAR + 4 OPTION YEARS',\n",
       " 'SAN BROCADE SWITCH SUPPORT',\n",
       " 'TRUE UP- MID SERVICE UPGRADE FROM STANDARD TO PREMIUM SUPPORT',\n",
       " 'VMWARE SUPPORT',\n",
       " 'I2 ANALYSTS NOTEBOOK SW SUBSCRIPTION AND SUPPORT FY20 RENEWAL',\n",
       " 'SPLUNK SUPPORT WITH OPTION YEARS',\n",
       " 'DELOITTE - ECM WEBAPPS REQUIREMENT 6MONTH BASE W/6 MONTH OPTION',\n",
       " 'THIS TASK ORDER AWARD IS FOR EST WEBAPP SUPPORT SERVICE 6 MONTH BASE (FUNDED) WITH 6 MONTH OPTION (UNFUNDED)',\n",
       " 'WEB SUBSCRIPTION 1 YEAR SERVICE',\n",
       " 'FFP FIXED PRICE FOR PLOTTER AND INSTALLER WITH ENCRYPTED HD',\n",
       " \"IBM I2 ANALYST'S NOTEBOOK CONCURRENT USER LICENSE + SW SUBSCRIPTION&SUPPORT 12 MONTHS\",\n",
       " 'WEBMETHODS EAIB SUPPORT',\n",
       " 'GSOC SUPPORT TOP SECRET']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in embeading features\n",
    "# bert_feat = pd.read_csv('bert/bert_embed.csv')\n",
    "\n",
    "# calculate cosine similarity of all contracts\n",
    "cosine_sim = pairwise_cosine_similarity(bert_feat.values)\n",
    "\n",
    "# top n contracts w. high similiarity score for contract of interest\n",
    "top_n_sim('SPLUNK SUPPORT WITH OPTION YEARS', award_desc_dict, cosine_sim, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract word embeddings of Splunk contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splunk = pd.read_csv('data/USA3_Splunk_slim.csv')\n",
    "splunk_feat = bert_sent_embedding(splunk.award_description.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure and rank order similarity between IRS contracts and Splunk contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>award_id_piid</th>\n",
       "      <th>award_description</th>\n",
       "      <th>BERT cosine similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2032H519F00784</td>\n",
       "      <td>WMQ BILLABLE SOFTWARE RENEWAL</td>\n",
       "      <td>0.926749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>2032H520F00499</td>\n",
       "      <td>ZEVA DECRYPTNABOX MAINTENANCE</td>\n",
       "      <td>0.922714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2032H520F00591</td>\n",
       "      <td>SILO SOFTWARE RENEWAL FOR CRIMINAL INVESTIGATION</td>\n",
       "      <td>0.921596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2032H519F00790</td>\n",
       "      <td>SILO SOFTWARE LICENSE AND SUPPORT FOR CRIMINAL...</td>\n",
       "      <td>0.920372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>2032H520F00930</td>\n",
       "      <td>EBS GSOC SECOPS SOLUTION</td>\n",
       "      <td>0.919565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2032H520F00031</td>\n",
       "      <td>AUDIOCODES MEDIA GATEWAYS FOR EEFAX BASE PERIO...</td>\n",
       "      <td>0.692216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>2032H520F00906</td>\n",
       "      <td>THE INTERNAL REVENUE SERVICE (IRS) INFORMATION...</td>\n",
       "      <td>0.691590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2032H520F00496</td>\n",
       "      <td>ENTERPRISE CASE MANAGEMENT (ECM) BPA TASK ORDE...</td>\n",
       "      <td>0.688282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2032H819F00229</td>\n",
       "      <td>THE PURPOSE OF THIS DELIVERY ORDER IS EXECUTE&amp;...</td>\n",
       "      <td>0.667566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>2032H520F00173</td>\n",
       "      <td>ENGINEERING SMES FOR IRS UNS NETWORK ENGINEERI...</td>\n",
       "      <td>0.535458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      award_id_piid                                  award_description  \\\n",
       "124  2032H519F00784                      WMQ BILLABLE SOFTWARE RENEWAL   \n",
       "622  2032H520F00499                      ZEVA DECRYPTNABOX MAINTENANCE   \n",
       "639  2032H520F00591   SILO SOFTWARE RENEWAL FOR CRIMINAL INVESTIGATION   \n",
       "151  2032H519F00790  SILO SOFTWARE LICENSE AND SUPPORT FOR CRIMINAL...   \n",
       "732  2032H520F00930                           EBS GSOC SECOPS SOLUTION   \n",
       "..              ...                                                ...   \n",
       "360  2032H520F00031  AUDIOCODES MEDIA GATEWAYS FOR EEFAX BASE PERIO...   \n",
       "795  2032H520F00906  THE INTERNAL REVENUE SERVICE (IRS) INFORMATION...   \n",
       "619  2032H520F00496  ENTERPRISE CASE MANAGEMENT (ECM) BPA TASK ORDE...   \n",
       "255  2032H819F00229  THE PURPOSE OF THIS DELIVERY ORDER IS EXECUTE&...   \n",
       "810  2032H520F00173  ENGINEERING SMES FOR IRS UNS NETWORK ENGINEERI...   \n",
       "\n",
       "     BERT cosine similarity  \n",
       "124                0.926749  \n",
       "622                0.922714  \n",
       "639                0.921596  \n",
       "151                0.920372  \n",
       "732                0.919565  \n",
       "..                      ...  \n",
       "360                0.692216  \n",
       "795                0.691590  \n",
       "619                0.688282  \n",
       "255                0.667566  \n",
       "810                0.535458  \n",
       "\n",
       "[924 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cosine similarity for each of splunk case with each of the data cases and then take mean\n",
    "dat['BERT cosine similarity'] = cosine_similarity(splunk_feat, bert_feat).mean(axis=0)\n",
    "\n",
    "# rank order\n",
    "dat = dat.sort_values(by=\"BERT cosine similarity\", ascending=False)\n",
    "\n",
    "dat[[\"award_id_piid\",\"award_description\", \"BERT cosine similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "dat[[\"award_id_piid\",\"award_description\", \"BERT cosine similarity\"]].to_csv('output/splunk_similarity_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure and rank order similarity between IRS contracts and any award description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually input award description \n",
    "award_description_rand = ['SPLUNK LICENCE RENEWAL']\n",
    "records = dat[[\"award_id_piid\",\"award_description\"]]\n",
    "\n",
    "r = similar_records_bert(20, award_description_rand, records, model='paraphrase-distilroberta-base-v1')\n",
    "\n",
    "for i, v in enumerate(award_description_rand):\n",
    "    print(r[i][['award_id_piid','award_description']], end =\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
